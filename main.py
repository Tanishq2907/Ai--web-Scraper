import streamlit as st
from scrape import scrape_website, split_dom_content
from parse import parse_with_ollama  # â† updated import

st.title("ğŸŒ Web Scraping AI")

url = st.text_input("Enter a website URL", placeholder="https://www.moneycontrol.com")
prompt = st.text_area("What to extract? (e.g. stock news headlines)", height=80)

if st.button("Scrape & Extract"):
    if not url:
        st.error("âŒ Please enter a URL.")
    elif not prompt:
        st.error("âŒ Please enter an extraction prompt.")
    else:
        st.info("ğŸ” Scraping site using ScrapingBee API (fallback: local Selenium)...")
        result = scrape_website(url)

        if result.get("error"):
            st.error(f"âŒ Scraping failed: {result['message']}")
            st.stop()

        st.success("âœ… Scraped successfully!")
        st.subheader("Page Title")
        st.write(result["title"])

        cleaned = result["cleaned_text"]
        if not cleaned.strip():
            st.warning("âš ï¸ No visible text extracted.")
            st.stop()

        st.subheader("Raw Extracted Text (preview)")
        st.write(cleaned[:500] + "â€¦")

        st.info("ğŸ¤– Sending For Extracting")
        chunks = split_dom_content(cleaned, 1000000)
        try:
            parsed = parse_with_ollama(chunks, prompt)
        except Exception as e:
            st.error(f"âŒ AI parsing failed: {e}")
            st.stop()

        st.success("âœ… Extraction complete")
        st.subheader("AI-Parsed Output")

        if isinstance(parsed, (list, dict)):
            st.json(parsed)
        else:
            st.write(parsed)
